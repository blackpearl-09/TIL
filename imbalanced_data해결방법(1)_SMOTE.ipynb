{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "imbalanced data해결방법(1)_SMOTE.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackpearl-09/TIL/blob/main/imbalanced_data%ED%95%B4%EA%B2%B0%EB%B0%A9%EB%B2%95(1)_SMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glJSVyOfLulE"
      },
      "source": [
        "#### 클래스 불균형 해결방법 (1) - 오버샘플링\n",
        "- 머신러닝을 통해 분류문제를 해결할 때, 학습을 통해 해당 데이터에 할당되는 클래스를 예측한다.  \n",
        "- 현실 세계에서는 클래스 불균형이 매우 심하다. 예를 들면, 공장 제조품의 불량 여부 or 카드 고객의 사기 여부 등 이런 경우는 수만 or수십만 건 중 하나. 이러한 경우 모델이 적은 수의 클래스(Minority)의 분포를 제대로 학습하지 못하게 됨. = 오버샘플링을 하는 이유\n",
        "\n",
        "\n",
        "\n",
        "- Random Over Sampling: 기존에 존재하는 소수의 클래스를 단순 복제하여 비율을 맞춰주는 방법.\n",
        " - 분포는 변화하지 않지만, 숫자가 늘어나기에 더 많은 가중치를 받게 되는 원리\n",
        " \n",
        " \n",
        "- SMOTE(Sythetic Minority Over-Sampling Technique)\n",
        "  : 임의의 소수 클래스 데이터로부터 인근 소수 클래스 사이에 새로운 데이터를 생성하는 방법. \n",
        "  - 임의의 소수 클래스에 해당하는 관측치 X를 잡고, X로부터 가장 가까운 K개의 이웃(NN; Nearest Neighbors)을 찾는다. 그리고 K개의 X(nn)와 관측치 X 사이에 임의의 새로운 데이터 X를 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMNHqKheLulM"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3ukmFh_LulM"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reprvUgVLulN"
      },
      "source": [
        "#### SMOTE import 방법. from imblearn.over_sampling import SMOTE \n",
        "  #pip install -U imbalanced-learn 패키지로부터\n",
        "\n",
        "- SMOTE 매개변수 \n",
        " - ratio : 초과 표본 비율 (다수 클래스의 표본 수 대비 소수 클래스의 표본 수)\n",
        "    - 초과 표본 비율을 자동으로 선택하려면 자동을 선택하고, 비율 값을 설정하려면 비율 설정(소수/다수)을 선택\n",
        " - kind : SMOTE 알고리즘 종류\n",
        " - k_neighbors: knn 적용할 숫자 (기본값: 5)\n",
        " - random_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEszvEmVLulN"
      },
      "source": [
        "### 알고리즘 종류\n",
        "#### - SMOTE는 특징이 연속적이고 분류 문제인 데이터를 합성하는 데 사용\n",
        "#### - 데이터가 혼합 된 경우  SMOTE-NC (Nominal and Continuous),  SMOTE 변형을 사용. WHY? 어떤 기능이 범주 형인지 표시해주기 때문에\n",
        "\n",
        "![image.png](attachment:image.png)"
      ]
    }
  ]
}